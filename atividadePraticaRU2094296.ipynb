{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scruzrafael/atividadePraticaNLP/blob/main/atividadePraticaRU2094296.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOTIVAÇÃO DO TRABALHO**\n",
        "\n",
        "*Com a grande difusão de notícias falsas pelas redes sociais, faz-se necessário ferramentas automáticas para verificação da veracidade das mesmas.\n",
        "Identificar a veracidade de uma notícia é um trabalho complexo até mesmo para profissionais\n",
        "da área de jornalismo e linguística. Sendo assim, uma ferramenta automatizada seria de grande\n",
        "ajuda para a sociedade.\n",
        "Sabendo disso, idealizamos esta atividade para que você possa treinar e aplicar seus\n",
        "conhecimentos adquiridos nas aulas teóricas e práticas, ao mesmo tempo que aplica seus\n",
        "conhecimentos em um projeto real e de grande utilidade pública.*\n",
        "\n",
        "*Utilizado o corpus FakeBr (https://github.com/roneysco/Fake.br-Corpus), que\n",
        "contém 7200 instâncias com 28 atributos e 1 rótulo em cada entrada/instância.\n",
        "Este corpus está rotulado de forma binária, sendo classificado em FAKE os textos falsos (3600 entradas) e REAL os textos verdadeiros (3600 entradas). Utilizado também imagens do repositório https://github.com/scruzrafael/atividadePraticaNLP.*\n",
        "  \n",
        "*Abaixo código referente a Atividade Prática. De já agradeço a atenção pela verificação da apresentação*\n",
        "\n",
        "\n",
        "**Rafael Sousa Cruz - RU 2094296**  \n",
        "*Natural Language Processing*\n",
        "\n",
        "*Tecnologia em Ciências de Dados*\n",
        "\n",
        "*Uninter*\n"
      ],
      "metadata": {
        "id": "Z9Yy7dAh4vNc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkQK4oQNlPPr"
      },
      "outputs": [],
      "source": [
        "#instalar bibliotecas utilizadas no projeto\n",
        "!pip install notebook wordcloud pillow numpy bs4 tqdm gitpython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH9o3AmMlXR7"
      },
      "outputs": [],
      "source": [
        "import git\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import numpy as np\n",
        "import PIL.Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsdAMKwqmZZQ"
      },
      "outputs": [],
      "source": [
        "#importar arquivo do repositorio\n",
        "def clone_github_repository(owner, repo, destination_path):\n",
        "    repository_url = f\"https://github.com/{owner}/{repo}.git\"\n",
        "\n",
        "    try:\n",
        "        git.Repo.clone_from(repository_url, destination_path)\n",
        "        print(f\"Repositório clonado com sucesso em {destination_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Falha ao clonar o repositório: {e}\")\n",
        "\n",
        "# Substitua 'roneysco' e 'Fake.br-Corpus' como os valores reais do proprietário e repositório\n",
        "clone_github_repository(owner='roneysco', repo='Fake.br-Corpus', destination_path='./Fake.br-Corpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxAQx2A1mdUt"
      },
      "outputs": [],
      "source": [
        "#importa arquivo csv com as informações de colunas selecionadas\n",
        "# caminho'/content/Fake.br-Corpus/preprocessed/pre-processed.csv' arquivo CSV\n",
        "ru_2094296 = '/content/Fake.br-Corpus/preprocessed/pre-processed.csv'\n",
        "\n",
        "# encoding='utf-8' para lidar com caracteres acentuados\n",
        "# Se houver problemas, tente utilizar encoding='latin1' ou encoding='ISO-8859-1'\n",
        "\n",
        "df_colunas = ['label', 'preprocessed_news']\n",
        "df = pd.read_csv(ru_2094296, encoding='utf-8', usecols=df_colunas, low_memory = False)\n",
        "\n",
        "#Visualizando as 10 primeiras linhas do DataFrame\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importar arquivos para imagens que serão utilizadas para carregar as wordclouds fake e true\n",
        "#git https://github.com/scruzrafael/atividadePratica-imagens\n",
        "def clone_github_repository(owner, repo, destination_path):\n",
        "    repository_url = f\"https://github.com/{owner}/{repo}.git\"\n",
        "\n",
        "    try:\n",
        "        git.Repo.clone_from(repository_url, destination_path)\n",
        "        print(f\"Repositório clonado com sucesso em {destination_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Falha ao clonar o repositório: {e}\")\n",
        "\n",
        "# Substitua 'scruzrafael' e 'atividadePratica-imagens' como os valores reais do proprietário e repositório\n",
        "clone_github_repository(owner='scruzrafael', repo='atividadePratica-imagens', destination_path='./atividadePratica-imagens')"
      ],
      "metadata": {
        "id": "dwMATGYCxkjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-LcWZO2mgrV"
      },
      "outputs": [],
      "source": [
        "#quantidade de instâncias\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5bN9N7omiUG"
      },
      "outputs": [],
      "source": [
        "# coluna chamada 'label'\n",
        "contagem_rotulos = df['label'].value_counts()\n",
        "\n",
        "# Exibindo a contagem de cada rótulo\n",
        "print(contagem_rotulos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuKWIbmDmkRX"
      },
      "outputs": [],
      "source": [
        "# coluna que contém as notícias pré-processadas\n",
        "coluna_noticias = 'preprocessed_news'\n",
        "\n",
        "# variável para armazenar a contagem total de palavras\n",
        "total_palavras = 0\n",
        "\n",
        "# Itere sobre as linhas do DataFrame\n",
        "for indice, linha in df.iterrows():\n",
        "    # string da coluna 'preprocessed_news'\n",
        "    noticia = linha[coluna_noticias]\n",
        "\n",
        "    # Dividir a string em palavras\n",
        "    palavras = noticia.split()\n",
        "\n",
        "    # contagem de palavras da linha ao total\n",
        "    total_palavras += len(palavras)\n",
        "\n",
        "# Exiba o total de palavras\n",
        "print(\"Total de palavras no corpus:\", total_palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MFj1ycsmmeX"
      },
      "outputs": [],
      "source": [
        "# Dividindo os dados em conjuntos de treinamento e teste\n",
        "df_treino, df_teste = train_test_split(df, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xot_YTfmok_"
      },
      "outputs": [],
      "source": [
        "# DataFrame com coluna 'preprocessed_news'\n",
        "coluna_noticias = 'preprocessed_news'\n",
        "\n",
        "# Criar um objeto TF-IDF Vectorizer com bigramas\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "# Aplicar o TF-IDF ao conjunto de treinamento\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_treino[coluna_noticias])\n",
        "\n",
        "# Obter as estatísticas desejadas (por exemplo, as top N palavras)\n",
        "# Neste exemplo, estamos usando SelectKBest para selecionar as top 50 palavras, 10% do total mostrado nas wordclouds (fake e true)\n",
        "k_best = SelectKBest(f_classif, k=50)\n",
        "X_tfidf_top = k_best.fit_transform(X_tfidf, df_treino['label'])\n",
        "\n",
        "# Exibir as top 10 palavras\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "top_feature_indices = k_best.get_support(indices=True)\n",
        "top_features = [feature_names[i] for i in top_feature_indices]\n",
        "\n",
        "print(\"Top 50 palavras usando TF-IDF e bigramas:\")\n",
        "print(top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIvJ2gUfmrBX"
      },
      "outputs": [],
      "source": [
        "# Separar as features (X) e os rótulos (y) do conjunto de treinamento\n",
        "X_treino = df_treino[coluna_noticias]\n",
        "y_treino = df_treino['label']\n",
        "\n",
        "# Separar as features (X) e os rótulos (y) do conjunto de teste\n",
        "X_teste = df_teste[coluna_noticias]\n",
        "y_teste = df_teste['label']\n",
        "\n",
        "modelo = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "    ('classificador', SVC())\n",
        "])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes = modelo.predict(X_teste)\n",
        "\n",
        "# Avaliar a acurácia\n",
        "acuracia = accuracy_score(y_teste, previsoes)\n",
        "\n",
        "print(\"Acurácia do modelo:\", acuracia)\n",
        "\n",
        "# Exibir o relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_teste, previsoes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUHWjZ0-ms4Y"
      },
      "outputs": [],
      "source": [
        "# Separar os dados rotulados como TRUE\n",
        "df_real = df[df['label'] == 'true']\n",
        "\n",
        "# Separar os dados em conjunto de treinamento e teste\n",
        "df_real_treino, df_real_teste = train_test_split(df_real, test_size=0.25, random_state=42)\n",
        "\n",
        "# Separar as features (X) e os rótulos (y) do conjunto de treinamento e teste\n",
        "X_real_treino = df_real_treino[coluna_noticias]\n",
        "y_real_treino = df_real_treino['label']\n",
        "\n",
        "X_real_teste = df_real_teste[coluna_noticias]\n",
        "y_real_teste = df_real_teste['label']\n",
        "\n",
        "# Criar um modelo de classificação usando Multinomial Naive Bayes\n",
        "modelo_real = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),  # Altere o ngram_range conforme necessário\n",
        "    ('classificador', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_real.fit(X_real_treino, y_real_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes_real = modelo_real.predict(X_real_teste)\n",
        "\n",
        "# Avaliar a acurácia do modelo\n",
        "acuracia_real = accuracy_score(y_real_teste, previsoes_real)\n",
        "\n",
        "# Obter as features (palavras, bigramas, trigramas)\n",
        "features = modelo_real.named_steps['vectorizer'].get_feature_names_out()\n",
        "\n",
        "# Exibir a quantidade de palavras, bigramas e trigramas\n",
        "quantidade_palavras = sum(' ' not in feature for feature in features)\n",
        "quantidade_bigramas = sum(' ' in feature for feature in features)\n",
        "quantidade_trigramas = sum(feature.count(' ') == 2 for feature in features)\n",
        "\n",
        "print(\"Quantidade de palavras usadas:\", quantidade_palavras)\n",
        "print(\"Quantidade de bigramas usados:\", quantidade_bigramas)\n",
        "print(\"Quantidade de trigramas usados:\", quantidade_trigramas)\n",
        "print(\"Acurácia do modelo para textos rotulados como TRUE:\", acuracia_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV9BV_I9mxNp"
      },
      "outputs": [],
      "source": [
        "# Separar os dados rotulados como FAKE\n",
        "df_real = df[df['label'] == 'fake']\n",
        "\n",
        "# Separar os dados em conjunto de treinamento e teste\n",
        "df_real_treino, df_real_teste = train_test_split(df_real, test_size=0.25, random_state=42)\n",
        "\n",
        "# Separar as features (X) e os rótulos (y) do conjunto de treinamento e teste\n",
        "X_real_treino = df_real_treino[coluna_noticias]\n",
        "y_real_treino = df_real_treino['label']\n",
        "\n",
        "X_real_teste = df_real_teste[coluna_noticias]\n",
        "y_real_teste = df_real_teste['label']\n",
        "\n",
        "# Criar um modelo de classificação usando Multinomial Naive Bayes\n",
        "modelo_real = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),  # Altere o ngram_range conforme necessário\n",
        "    ('classificador', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_real.fit(X_real_treino, y_real_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes_real = modelo_real.predict(X_real_teste)\n",
        "\n",
        "# Avaliar a acurácia do modelo\n",
        "acuracia_real = accuracy_score(y_real_teste, previsoes_real)\n",
        "\n",
        "# Obter as features (palavras, bigramas, trigramas)\n",
        "features = modelo_real.named_steps['vectorizer'].get_feature_names_out()\n",
        "\n",
        "# Exibir a quantidade de palavras, bigramas e trigramas\n",
        "quantidade_palavras = sum(' ' not in feature for feature in features)\n",
        "quantidade_bigramas = sum(' ' in feature for feature in features)\n",
        "quantidade_trigramas = sum(feature.count(' ') == 2 for feature in features)\n",
        "\n",
        "print(\"Quantidade de palavras usadas:\", quantidade_palavras)\n",
        "print(\"Quantidade de bigramas usados:\", quantidade_bigramas)\n",
        "print(\"Quantidade de trigramas usados:\", quantidade_trigramas)\n",
        "print(\"Acurácia do modelo para textos rotulados como FAKE:\", acuracia_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PllJdIFLniL-"
      },
      "outputs": [],
      "source": [
        "#importar máscara da imagem de fundo TRUE\n",
        "imagem_mascara = np.array(PIL.Image.open(\"/content/atividadePratica-imagens/positiv.jpg\"))\n",
        "\n",
        "imagem_mascara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOXUaDE5nnbn"
      },
      "outputs": [],
      "source": [
        "# Adicione as previsões ao DataFrame de teste\n",
        "df_teste['previsoes'] = previsoes\n",
        "\n",
        "# Separe os textos por classe\n",
        "text_real = ' '.join(df_teste[df_teste['previsoes'] == 'true'][coluna_noticias])\n",
        "\n",
        "wordcloud = WordCloud(background_color='white',\n",
        "                      max_words=500,\n",
        "                      mask=imagem_mascara,\n",
        "                      contour_color=\"grey\",\n",
        "                      contour_width=0.3,\n",
        "                      min_font_size=3,\n",
        "                      random_state=42).generate(text_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxZUyPZgnuaA"
      },
      "outputs": [],
      "source": [
        "# Mostrando a imagem\n",
        "def gerar_wordcloud(texto, titulo):\n",
        "  plt.figure(figsize = (8, 8), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "\n",
        "  #plt.title(titulo)\n",
        "\n",
        "#remove os eixos do gráfico\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad=0)\n",
        "  plt.text(-0.07, 0.5, titulo, transform=plt.gca().transAxes, rotation=90, va='center', ha='left', fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "# Gerar nuvem de palavras para FAKE\n",
        "gerar_wordcloud(text_real, 'RU2094296 - RAFAEL SOUSA CRUZ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avbVeUuMoSkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa455f54-5578-433b-9374-8195165ddf24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wordcloud.wordcloud.WordCloud at 0x7edcd7777fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#gravar imagem no caminho /content/wordCloudTrue.png\n",
        "wordcloud.to_file('/content/wordCloudTrue.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aKdG_Jhm1Bx"
      },
      "outputs": [],
      "source": [
        "#importar máscara da imagem de fundo FAKE\n",
        "imagem_mascara = np.array(PIL.Image.open(\"/content/atividadePratica-imagens/negativ.jpg\"))\n",
        "\n",
        "imagem_mascara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWXeb429nFR6"
      },
      "outputs": [],
      "source": [
        "# Adicione as previsões ao DataFrame de teste\n",
        "df_teste['previsoes'] = previsoes\n",
        "\n",
        "# Separe os textos por classe\n",
        "text_fake = ' '.join(df_teste[df_teste['previsoes'] == 'fake'][coluna_noticias])\n",
        "\n",
        "wordcloud = WordCloud(background_color='white',\n",
        "                      max_words=500,\n",
        "                      mask=imagem_mascara,\n",
        "                      contour_color=\"grey\",\n",
        "                      contour_width=0.3,\n",
        "                      min_font_size=3,\n",
        "                      random_state=42).generate(text_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjAh_75inH_7"
      },
      "outputs": [],
      "source": [
        "# Mostrando a imagem\n",
        "def gerar_wordcloud(texto, titulo):\n",
        "  plt.figure(figsize = (8, 8), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "\n",
        "  #plt.title(titulo)\n",
        "\n",
        "#remove os eixos do gráfico\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad=0)\n",
        "  plt.text(-0.07, 0.5, titulo, transform=plt.gca().transAxes, rotation=90, va='center', ha='left', fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "# Gerar nuvem de palavras para FAKE\n",
        "gerar_wordcloud(text_fake, 'RU2094296 - RAFAEL SOUSA CRUZ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxkNTBy0nUzk"
      },
      "outputs": [],
      "source": [
        "#gravar imagem no caminho /content/wordCloudFake.png\n",
        "wordcloud.to_file('/content/wordCloudFake.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}