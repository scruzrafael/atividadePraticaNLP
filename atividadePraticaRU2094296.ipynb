{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scruzrafael/atividadePraticaNLP/blob/main/atividadePraticaRU2094296.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkQK4oQNlPPr",
        "outputId": "785481d6-0c13-4ba0-a81b-d32b5116b11c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (6.5.5)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (3.1.41)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook) (3.1.3)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.3.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook) (23.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from notebook) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook) (5.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8,>=5.3.4->notebook) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (4.9.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (2.1.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (23.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (2.16.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->notebook) (7.34.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (3.0.43)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (1.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8,>=5.3.4->notebook) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook) (2.21)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "#instalar bibliotecas utilizadas no projeto\n",
        "!pip install notebook wordcloud pillow numpy bs4 tqdm gitpython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kH9o3AmMlXR7"
      },
      "outputs": [],
      "source": [
        "import git\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import numpy as np\n",
        "import PIL.Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsdAMKwqmZZQ"
      },
      "outputs": [],
      "source": [
        "#importar arquivo do repositorio\n",
        "def clone_github_repository(owner, repo, destination_path):\n",
        "    repository_url = f\"https://github.com/{owner}/{repo}.git\"\n",
        "\n",
        "    try:\n",
        "        git.Repo.clone_from(repository_url, destination_path)\n",
        "        print(f\"Repositório clonado com sucesso em {destination_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Falha ao clonar o repositório: {e}\")\n",
        "\n",
        "# Substitua 'roneysco' e 'Fake.br-Corpus' como os valores reais do proprietário e repositório\n",
        "clone_github_repository(owner='roneysco', repo='Fake.br-Corpus', destination_path='./Fake.br-Corpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxAQx2A1mdUt"
      },
      "outputs": [],
      "source": [
        "#importa arquivo csv com as informações de colunas selecionadas\n",
        "# caminho'/content/Fake.br-Corpus/preprocessed/pre-processed.csv' arquivo CSV\n",
        "ru_2094296 = '/content/Fake.br-Corpus/preprocessed/pre-processed.csv'\n",
        "\n",
        "# encoding='utf-8' para lidar com caracteres acentuados\n",
        "# Se houver problemas, tente utilizar encoding='latin1' ou encoding='ISO-8859-1'\n",
        "\n",
        "df_colunas = ['label', 'preprocessed_news']\n",
        "df = pd.read_csv(ru_2094296, encoding='utf-8', usecols=df_colunas, low_memory = False)\n",
        "\n",
        "#Visualizando as 10 primeiras linhas do DataFrame\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-LcWZO2mgrV"
      },
      "outputs": [],
      "source": [
        "#quantidade de instâncias\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5bN9N7omiUG"
      },
      "outputs": [],
      "source": [
        "# coluna chamada 'label'\n",
        "contagem_rotulos = df['label'].value_counts()\n",
        "\n",
        "# Exibindo a contagem de cada rótulo\n",
        "print(contagem_rotulos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuKWIbmDmkRX"
      },
      "outputs": [],
      "source": [
        "# coluna que contém as notícias pré-processadas\n",
        "coluna_noticias = 'preprocessed_news'\n",
        "\n",
        "# variável para armazenar a contagem total de palavras\n",
        "total_palavras = 0\n",
        "\n",
        "# Itere sobre as linhas do DataFrame\n",
        "for indice, linha in df.iterrows():\n",
        "    # string da coluna 'preprocessed_news'\n",
        "    noticia = linha[coluna_noticias]\n",
        "\n",
        "    # Dividir a string em palavras\n",
        "    palavras = noticia.split()\n",
        "\n",
        "    # contagem de palavras da linha ao total\n",
        "    total_palavras += len(palavras)\n",
        "\n",
        "# Exiba o total de palavras\n",
        "print(\"Total de palavras no corpus:\", total_palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MFj1ycsmmeX"
      },
      "outputs": [],
      "source": [
        "# Dividindo os dados em conjuntos de treinamento e teste\n",
        "df_treino, df_teste = train_test_split(df, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xot_YTfmok_"
      },
      "outputs": [],
      "source": [
        "# DataFrame com coluna 'preprocessed_news'\n",
        "coluna_noticias = 'preprocessed_news'\n",
        "\n",
        "# Criar um objeto TF-IDF Vectorizer com bigramas\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "# Aplicar o TF-IDF ao conjunto de treinamento\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_treino[coluna_noticias])\n",
        "\n",
        "# Obter as estatísticas desejadas (por exemplo, as top N palavras)\n",
        "# Neste exemplo, estamos usando SelectKBest para selecionar as top 50 palavras, 10% do total mostrado nas wordclouds (fake e true)\n",
        "k_best = SelectKBest(f_classif, k=50)\n",
        "X_tfidf_top = k_best.fit_transform(X_tfidf, df_treino['label'])\n",
        "\n",
        "# Exibir as top 10 palavras\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "top_feature_indices = k_best.get_support(indices=True)\n",
        "top_features = [feature_names[i] for i in top_feature_indices]\n",
        "\n",
        "print(\"Top 50 palavras usando TF-IDF e bigramas:\")\n",
        "print(top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIvJ2gUfmrBX"
      },
      "outputs": [],
      "source": [
        "# Separar as features (X) e os rótulos (y) do conjunto de treinamento\n",
        "X_treino = df_treino[coluna_noticias]\n",
        "y_treino = df_treino['label']\n",
        "\n",
        "# Separar as features (X) e os rótulos (y) do conjunto de teste\n",
        "X_teste = df_teste[coluna_noticias]\n",
        "y_teste = df_teste['label']\n",
        "\n",
        "modelo = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
        "    ('classificador', SVC())\n",
        "])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes = modelo.predict(X_teste)\n",
        "\n",
        "# Avaliar a acurácia\n",
        "acuracia = accuracy_score(y_teste, previsoes)\n",
        "\n",
        "print(\"Acurácia do modelo:\", acuracia)\n",
        "\n",
        "# Exibir o relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_teste, previsoes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUHWjZ0-ms4Y"
      },
      "outputs": [],
      "source": [
        "# Separar os dados rotulados como TRUE\n",
        "df_real = df[df['label'] == 'true']\n",
        "\n",
        "# Separar os dados em conjunto de treinamento e teste\n",
        "df_real_treino, df_real_teste = train_test_split(df_real, test_size=0.25, random_state=42)\n",
        "\n",
        "# Separar as features (X) e os rótulos (y) do conjunto de treinamento e teste\n",
        "X_real_treino = df_real_treino[coluna_noticias]\n",
        "y_real_treino = df_real_treino['label']\n",
        "\n",
        "X_real_teste = df_real_teste[coluna_noticias]\n",
        "y_real_teste = df_real_teste['label']\n",
        "\n",
        "# Criar um modelo de classificação usando Multinomial Naive Bayes\n",
        "modelo_real = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),  # Altere o ngram_range conforme necessário\n",
        "    ('classificador', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_real.fit(X_real_treino, y_real_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes_real = modelo_real.predict(X_real_teste)\n",
        "\n",
        "# Avaliar a acurácia do modelo\n",
        "acuracia_real = accuracy_score(y_real_teste, previsoes_real)\n",
        "\n",
        "# Obter as features (palavras, bigramas, trigramas)\n",
        "features = modelo_real.named_steps['vectorizer'].get_feature_names_out()\n",
        "\n",
        "# Exibir a quantidade de palavras, bigramas e trigramas\n",
        "quantidade_palavras = sum(' ' not in feature for feature in features)\n",
        "quantidade_bigramas = sum(' ' in feature for feature in features)\n",
        "quantidade_trigramas = sum(feature.count(' ') == 2 for feature in features)\n",
        "\n",
        "print(\"Quantidade de palavras usadas:\", quantidade_palavras)\n",
        "print(\"Quantidade de bigramas usados:\", quantidade_bigramas)\n",
        "print(\"Quantidade de trigramas usados:\", quantidade_trigramas)\n",
        "print(\"Acurácia do modelo para textos rotulados como TRUE:\", acuracia_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV9BV_I9mxNp"
      },
      "outputs": [],
      "source": [
        "# Separar os dados rotulados como FAKE\n",
        "df_real = df[df['label'] == 'fake']\n",
        "\n",
        "# Separar os dados em conjunto de treinamento e teste\n",
        "df_real_treino, df_real_teste = train_test_split(df_real, test_size=0.25, random_state=42)\n",
        "\n",
        "# Separar as features (X) e os rótulos (y) do conjunto de treinamento e teste\n",
        "X_real_treino = df_real_treino[coluna_noticias]\n",
        "y_real_treino = df_real_treino['label']\n",
        "\n",
        "X_real_teste = df_real_teste[coluna_noticias]\n",
        "y_real_teste = df_real_teste['label']\n",
        "\n",
        "# Criar um modelo de classificação usando Multinomial Naive Bayes\n",
        "modelo_real = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),  # Altere o ngram_range conforme necessário\n",
        "    ('classificador', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Treinar o modelo\n",
        "modelo_real.fit(X_real_treino, y_real_treino)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes_real = modelo_real.predict(X_real_teste)\n",
        "\n",
        "# Avaliar a acurácia do modelo\n",
        "acuracia_real = accuracy_score(y_real_teste, previsoes_real)\n",
        "\n",
        "# Obter as features (palavras, bigramas, trigramas)\n",
        "features = modelo_real.named_steps['vectorizer'].get_feature_names_out()\n",
        "\n",
        "# Exibir a quantidade de palavras, bigramas e trigramas\n",
        "quantidade_palavras = sum(' ' not in feature for feature in features)\n",
        "quantidade_bigramas = sum(' ' in feature for feature in features)\n",
        "quantidade_trigramas = sum(feature.count(' ') == 2 for feature in features)\n",
        "\n",
        "print(\"Quantidade de palavras usadas:\", quantidade_palavras)\n",
        "print(\"Quantidade de bigramas usados:\", quantidade_bigramas)\n",
        "print(\"Quantidade de trigramas usados:\", quantidade_trigramas)\n",
        "print(\"Acurácia do modelo para textos rotulados como FAKE:\", acuracia_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PllJdIFLniL-"
      },
      "outputs": [],
      "source": [
        "#importar máscara da imagem de fundo TRUE\n",
        "imagem_mascara = np.array(PIL.Image.open(\"/content/positiv.jpg\"))\n",
        "\n",
        "imagem_mascara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOXUaDE5nnbn"
      },
      "outputs": [],
      "source": [
        "# Adicione as previsões ao DataFrame de teste\n",
        "df_teste['previsoes'] = previsoes\n",
        "\n",
        "# Separe os textos por classe\n",
        "text_real = ' '.join(df_teste[df_teste['previsoes'] == 'true'][coluna_noticias])\n",
        "\n",
        "wordcloud = WordCloud(background_color='white',\n",
        "                      max_words=500,\n",
        "                      mask=imagem_mascara,\n",
        "                      contour_color=\"grey\",\n",
        "                      contour_width=0.3,\n",
        "                      min_font_size=3,\n",
        "                      random_state=42).generate(text_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxZUyPZgnuaA"
      },
      "outputs": [],
      "source": [
        "# Mostrando a imagem\n",
        "def gerar_wordcloud(texto, titulo):\n",
        "  plt.figure(figsize = (8, 8), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "\n",
        "  #plt.title(titulo)\n",
        "\n",
        "#remove os eixos do gráfico\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad=0)\n",
        "  plt.text(-0.07, 0.5, titulo, transform=plt.gca().transAxes, rotation=90, va='center', ha='left', fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "# Gerar nuvem de palavras para FAKE\n",
        "gerar_wordcloud(text_real, 'RU2094296')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avbVeUuMoSkl"
      },
      "outputs": [],
      "source": [
        "wordcloud.to_file('/content/wordCloudTrue.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aKdG_Jhm1Bx"
      },
      "outputs": [],
      "source": [
        "#importar máscara da imagem de fundo FAKE\n",
        "imagem_mascara = np.array(PIL.Image.open(\"/content/negativ.jpg\"))\n",
        "\n",
        "imagem_mascara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWXeb429nFR6"
      },
      "outputs": [],
      "source": [
        "# Adicione as previsões ao DataFrame de teste\n",
        "df_teste['previsoes'] = previsoes\n",
        "\n",
        "# Separe os textos por classe\n",
        "text_fake = ' '.join(df_teste[df_teste['previsoes'] == 'fake'][coluna_noticias])\n",
        "\n",
        "wordcloud = WordCloud(background_color='white',\n",
        "                      max_words=500,\n",
        "                      mask=imagem_mascara,\n",
        "                      contour_color=\"grey\",\n",
        "                      contour_width=0.3,\n",
        "                      min_font_size=3,\n",
        "                      random_state=42).generate(text_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjAh_75inH_7"
      },
      "outputs": [],
      "source": [
        "# Mostrando a imagem\n",
        "def gerar_wordcloud(texto, titulo):\n",
        "  plt.figure(figsize = (8, 8), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "\n",
        "  #plt.title(titulo)\n",
        "\n",
        "#remove os eixos do gráfico\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad=0)\n",
        "  plt.text(-0.07, 0.5, titulo, transform=plt.gca().transAxes, rotation=90, va='center', ha='left', fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "# Gerar nuvem de palavras para FAKE\n",
        "gerar_wordcloud(text_fake, 'RU2094296')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxkNTBy0nUzk"
      },
      "outputs": [],
      "source": [
        "wordcloud.to_file('/content/wordCloudFake.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgqOA6R2cwWswF4mm9YcMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}